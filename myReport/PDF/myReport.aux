\relax 
\providecommand \oddpage@label [2]{}
\citation{preotiuc-pietro_automatically_2019}
\citation{preotiuc-pietro_automatically_2019}
\citation{bhargavaGeneralizationNLIWays2021}
\citation{nguyenBERTweetPretrainedLanguage2020}
\citation{sunMobileBERTCompactTaskAgnostic2020}
\citation{sanhDistilBERTDistilledVersion2020}
\citation{jinModelingSeverityComplaints2021}
\citation{olshtain_speechact_1987}
\citation{brownPolitenessUniversalsLanguage1987}
\citation{tripp_when_2011}
\citation{balaji_customer_2015}
\citation{preotiuc-pietro_automatically_2019}
\citation{liang_dictionary-based_2006}
\citation{coussement_improving_2008}
\citation{preotiuc-pietro_automatically_2019}
\citation{jin_complaint_2020}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Background}{1}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Sample complaints extracted from Twitter, exhibiting diverse degrees of complaint expression and severity. These complaints are sourced from data that has undergone the preprocessing steps outlined in Chapter 3.\relax }}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab: ex_complaints}{{1.1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aims and Objectives}{2}{}\protected@file@percent }
\citation{olshtain_speechact_1987}
\citation{sparksComplainingCyberspaceMotives2010}
\citation{olshtain_speechact_1987}
\citation{brownPolitenessUniversalsLanguage1987}
\citation{boxerSocialDistanceSpeech1993}
\citation{sharma_complainers_2010}
\citation{rookNormativeInfluencesImpulsive1995}
\citation{bechererSelfMonitoringModeratingVariable1978}
\citation{sharma_complainers_2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Literature Survey}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The act of complaining}{3}{}\protected@file@percent }
\citation{tripp_when_2011}
\citation{tripp_when_2011}
\citation{tripp_when_2011}
\citation{hennig-thurauElectronicWordofmouthConsumeropinion2004}
\citation{sparksComplainingCyberspaceMotives2010}
\citation{sparksComplainingCyberspaceMotives2010}
\citation{sparksComplainingCyberspaceMotives2010}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Complaining online}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Complaining in social media}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Self-expression on Twitter}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Transformers}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Ongoing research}{6}{}\protected@file@percent }
\citation{preotiuc-pietro_automatically_2019}
\citation{preotiuc-pietro_automatically_2019}
\citation{jin_complaint_2020}
\citation{jinModelingSeverityComplaints2021}
\citation{preotiuc-pietro_automatically_2019}
\citation{preotiuc-pietro_automatically_2019}
\citation{luiLangidPyOfftheshelf2012}
\citation{preotiuc-pietro_automatically_2019}
\citation{preotiuc-pietro_automatically_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Methodology}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Task}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data and pre-processing}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Criteria for tweets}{7}{}\protected@file@percent }
\citation{olshtain_speechact_1987}
\citation{artsteinInterCoderAgreementComputational2008}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The nine domains and the distribution of tweets that are complaints and those that are not. The percentages indicate how the splits are distributed \cite  {preotiuc-pietro_automatically_2019}.\relax }}{8}{}\protected@file@percent }
\newlabel{tab: domains}{{3.1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Data Extraction}{8}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Selection of tweets based on random sampling and where they have received replies when addressed to the 93 customer service handles combined with random sampled tweets that are addressed to other handles (random\_reply) and tweets that are not addressed to any handle (random\_tweet) \cite  {preotiuc-pietro_automatically_2019}.\relax }}{8}{}\protected@file@percent }
\newlabel{tab: tweet_counts}{{3.2}{8}}
\citation{devlinBERTPretrainingDeep2018}
\citation{vaswaniAttentionAllYou2023a}
\citation{chungEmpiricalEvaluationGated2014}
\citation{hochreiterLongShortTermMemory1997}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Annotation}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Environment}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Hardware}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Software}{9}{}\protected@file@percent }
\citation{bhargavaGeneralizationNLIWays2021}
\citation{nguyenBERTweetPretrainedLanguage2020}
\citation{sunMobileBERTCompactTaskAgnostic2020}
\citation{sanhDistilBERTDistilledVersion2020}
\citation{bhargavaGeneralizationNLIWays2021}
\citation{nguyenBERTweetPretrainedLanguage2020}
\citation{sunMobileBERTCompactTaskAgnostic2020}
\citation{sanhDistilBERTDistilledVersion2020}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Software and library versions used for this project. Other more \relax }}{10}{}\protected@file@percent }
\newlabel{tab: libs_used}{{3.3}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Model selection}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Data tokenisation}{10}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces The transformer models used for the experiments along with type of tokenization, and vocabulary size and sorted by the number of parameters for each of them. The parameter counts are from \cite  {bhargavaGeneralizationNLIWays2021} for Roberta, Bert, Albert and Bert Tiny. For Bertweet it is from \cite  {nguyenBERTweetPretrainedLanguage2020}, MobileBert from \cite  {sunMobileBERTCompactTaskAgnostic2020} and Distilbert from \cite  {sanhDistilBERTDistilledVersion2020}.\relax }}{11}{}\protected@file@percent }
\newlabel{tab: model_dtls}{{3.4}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Tokenization methods}{11}{}\protected@file@percent }
\citation{preotiuc-pietro_automatically_2019}
\citation{jinModelingSeverityComplaints2021}
\citation{preotiuc-pietro_automatically_2019}
\citation{jinModelingSeverityComplaints2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Choice of settings}{12}{}\protected@file@percent }
\newlabel{fig: token_hist}{{3.1a}{12}}
\newlabel{sub@fig: token_hist}{{a}{12}}
\newlabel{fig: token_pp_hist}{{3.1b}{12}}
\newlabel{sub@fig: token_pp_hist}{{b}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The token count distribution for the full dataset of 3,449 tweets before and after tokenization with the red dashed line indicating 95\% coverage of tweets. BertTokenizer is used here.\relax }}{12}{}\protected@file@percent }
\newlabel{fig: bef_aft_token}{{3.1}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Tokenisation example}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Experiments set 1: Performance comparison of BERT variants}{13}{}\protected@file@percent }
\citation{preotiuc-pietro_automatically_2019}
\citation{preotiuc-pietro_automatically_2019}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces The choice of key parameters and hyperparameters used for Experiment 1.\relax }}{14}{}\protected@file@percent }
\newlabel{tab: exp1_params}{{3.5}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Experiments set 2: Cross-domain performance}{15}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces The choice of key parameters and hyperparameters used for Experiment 2. Refer to the Chapter on results for the model and learning rate used for this experiment. \relax }}{15}{}\protected@file@percent }
\newlabel{tab: exp2_params}{{3.6}{15}}
\citation{preotiuc-pietro_automatically_2019}
\citation{jinModelingSeverityComplaints2021}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Ethical, Professional and Legal Issues}{16}{}\protected@file@percent }
\citation{preotiuc-pietro_automatically_2019}
\citation{jinModelingSeverityComplaints2021}
\citation{preotiuc-pietro_automatically_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Results and discussion}{17}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Data exploration}{17}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustrates the distribution of tweets categorised as 'complaints' and 'not complaints', with random 'tweets / replies' shown separately.\relax }}{17}{}\protected@file@percent }
\newlabel{fig: compl_non_random_dist}{{4.1}{17}}
\newlabel{fig: domain_dist_pct}{{4.2a}{18}}
\newlabel{sub@fig: domain_dist_pct}{{a}{18}}
\newlabel{fig: domain_dist_count}{{4.2b}{18}}
\newlabel{sub@fig: domain_dist_count}{{b}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Shows the distribution of the domains used in the dataset\relax }}{18}{}\protected@file@percent }
\newlabel{fig: compl_main_dist}{{4.2}{18}}
\newlabel{fig: top_ngrams}{{4.3a}{18}}
\newlabel{sub@fig: top_ngrams}{{a}{18}}
\newlabel{fig: top_hashtags}{{4.3b}{18}}
\newlabel{sub@fig: top_hashtags}{{b}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Top n-grams(excl. unigrams) and hashtags in the complaint tweets.\relax }}{18}{}\protected@file@percent }
\newlabel{fig: top_ngrams_hashtags}{{4.3}{18}}
\citation{perezPysentimientoPythonToolkit2021}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Distribution of positive, negative and neutral sentiments in the tweets.\relax }}{20}{}\protected@file@percent }
\newlabel{fig: sentiment}{{4.4}{20}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Statistics of tweets in the dataset.\relax }}{20}{}\protected@file@percent }
\newlabel{tab: tweets_statistics}{{4.1}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Comparision of model performance}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Analysis of best performing model}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Cross-domain results}{21}{}\protected@file@percent }
\bibstyle{acm}
\bibdata{mybibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{22}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{artsteinInterCoderAgreementComputational2008}{1}
\bibcite{balaji_customer_2015}{2}
\bibcite{bechererSelfMonitoringModeratingVariable1978}{3}
\bibcite{bhargavaGeneralizationNLIWays2021}{4}
\bibcite{boxerSocialDistanceSpeech1993}{5}
\bibcite{brownPolitenessUniversalsLanguage1987}{6}
\bibcite{chungEmpiricalEvaluationGated2014}{7}
\bibcite{coussement_improving_2008}{8}
\bibcite{devlinBERTPretrainingDeep2018}{9}
\bibcite{hennig-thurauElectronicWordofmouthConsumeropinion2004}{10}
\bibcite{hochreiterLongShortTermMemory1997}{11}
\bibcite{jin_complaint_2020}{12}
\bibcite{jinModelingSeverityComplaints2021}{13}
\bibcite{liang_dictionary-based_2006}{14}
\bibcite{luiLangidPyOfftheshelf2012}{15}
\bibcite{nguyenBERTweetPretrainedLanguage2020}{16}
\bibcite{olshtain_speechact_1987}{17}
\bibcite{preotiuc-pietro_automatically_2019}{18}
\bibcite{perezPysentimientoPythonToolkit2021}{19}
\bibcite{rookNormativeInfluencesImpulsive1995}{20}
\bibcite{sanhDistilBERTDistilledVersion2020}{21}
\bibcite{sharma_complainers_2010}{22}
\bibcite{sparksComplainingCyberspaceMotives2010}{23}
\bibcite{sunMobileBERTCompactTaskAgnostic2020}{24}
\bibcite{tripp_when_2011}{25}
\bibcite{vaswaniAttentionAllYou2023a}{26}
\@writefile{toc}{\contentsline {chapter}{Appendices}{26}{}\protected@file@percent }
\citation{jinModelingSeverityComplaints2021}
\citation{jinModelingSeverityComplaints2021}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Additional graphs and analysis}{27}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Breakdown of tweets in full dataset}{27}{}\protected@file@percent }
\newlabel{sec: apdxa_fulldataset}{{A.1}{27}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces The nine domains and the distribution of tweets that are complaints and those that are not from the latest of the dataset available at https://archive.org/details/complaint\_severity\_data and as used for the experiments. Additionally, the table includes the number of random tweets and replies introduced into the dataset by the authors for a more proportionate representation of the classes.\relax }}{27}{}\protected@file@percent }
\newlabel{tab: fulldataset_breakdown}{{A.1}{27}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Sample data from dataset}{27}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Sample data from \cite  {jinModelingSeverityComplaints2021}.\relax }}{28}{}\protected@file@percent }
\newlabel{tab: apdx_sample_data}{{A.2}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Token distribution after tokenization}{28}{}\protected@file@percent }
\newlabel{sec: apdxa_token_dist}{{A.3}{28}}
\newlabel{fig: token_pp_hist_albert}{{A.1a}{29}}
\newlabel{sub@fig: token_pp_hist_albert}{{a}{29}}
\newlabel{fig: token_pp_hist_bertwteet}{{A.1b}{29}}
\newlabel{sub@fig: token_pp_hist_bertwteet}{{b}{29}}
\newlabel{fig: token_pp_hist_tiny}{{A.1c}{29}}
\newlabel{sub@fig: token_pp_hist_tiny}{{c}{29}}
\newlabel{fig: token_pp_hist_distilbert}{{A.1d}{29}}
\newlabel{sub@fig: token_pp_hist_distilbert}{{d}{29}}
\newlabel{fig: token_pp_hist_mobile}{{A.1e}{29}}
\newlabel{sub@fig: token_pp_hist_mobile}{{e}{29}}
\newlabel{fig: token_pp_hist_roberta}{{A.1f}{29}}
\newlabel{sub@fig: token_pp_hist_roberta}{{f}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces The token count distribution for the full dataset of 3,449 tweets for all models.\relax }}{29}{}\protected@file@percent }
\newlabel{fig: apdxa_tokens}{{A.1}{29}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Other references}{30}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Code Repository}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Model references}{30}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces The transformer models used for the experiments and links to their documentation.\relax }}{30}{}\protected@file@percent }
\newlabel{tab: apdxb_model_doc}{{B.1}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Evaluation metrics references}{30}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces The metrics used for evaluating the performance of the experiments and links to their documentation.\relax }}{31}{}\protected@file@percent }
\newlabel{tab: apdxb_metric_doc}{{B.2}{31}}
\gdef \@abspage@last{38}
