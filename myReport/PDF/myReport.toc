\contentsline {chapter}{\numberline {1}Introduction}{1}{}%
\contentsline {section}{\numberline {1.1}Background}{1}{}%
\contentsline {section}{\numberline {1.2}Aims and Objectives}{2}{}%
\contentsline {chapter}{\numberline {2}Literature Survey}{3}{}%
\contentsline {section}{\numberline {2.1}The act of complaining}{3}{}%
\contentsline {section}{\numberline {2.2}Complaining online}{4}{}%
\contentsline {section}{\numberline {2.3}Complaining in social media}{5}{}%
\contentsline {section}{\numberline {2.4}Twitter as a medium for self-expression}{7}{}%
\contentsline {section}{\numberline {2.5}NLP approaches for text classification}{8}{}%
\contentsline {subsection}{\numberline {2.5.1}Recurrent Neural Networks}{9}{}%
\contentsline {subsection}{\numberline {2.5.2}Transformer and inductive transfer learning}{10}{}%
\contentsline {subsection}{\numberline {2.5.3}BERT and its variants}{11}{}%
\contentsline {section}{\numberline {2.6}Ongoing research}{11}{}%
\contentsline {chapter}{\numberline {3}Methodology}{12}{}%
\contentsline {section}{\numberline {3.1}Task}{12}{}%
\contentsline {section}{\numberline {3.2}Data and pre-processing}{12}{}%
\contentsline {subsection}{\numberline {3.2.1}Criteria for Tweets}{12}{}%
\contentsline {subsection}{\numberline {3.2.2}Data Extraction}{12}{}%
\contentsline {subsection}{\numberline {3.2.3}Annotation}{13}{}%
\contentsline {section}{\numberline {3.3}Environment}{14}{}%
\contentsline {subsection}{\numberline {3.3.1}Hardware}{14}{}%
\contentsline {subsection}{\numberline {3.3.2}Software}{14}{}%
\contentsline {section}{\numberline {3.4}Model selection}{15}{}%
\contentsline {section}{\numberline {3.5}Data tokenisation}{15}{}%
\contentsline {subsection}{\numberline {3.5.1}Tokenization methods}{16}{}%
\contentsline {subsection}{\numberline {3.5.2}Choice of settings}{16}{}%
\contentsline {subsection}{\numberline {3.5.3}Tokenisation example}{17}{}%
\contentsline {section}{\numberline {3.6}Experiments set 1: Predictive performance comparison of BERT variants}{18}{}%
\contentsline {section}{\numberline {3.7}Experiments set 2: Cross-domain predictive performance comparison}{19}{}%
\contentsline {section}{\numberline {3.8}Ethical, Professional and Legal Issues}{21}{}%
\contentsline {chapter}{\numberline {4}Results and discussion}{22}{}%
\contentsline {section}{\numberline {4.1}Data exploration}{22}{}%
\contentsline {subsection}{\numberline {4.1.1}Domain and class distribution}{22}{}%
\contentsline {subsection}{\numberline {4.1.2}Linguistic analysis}{23}{}%
\contentsline {subsection}{\numberline {4.1.3}Sentiment analysis}{25}{}%
\contentsline {subsection}{\numberline {4.1.4}Key statistics}{26}{}%
\contentsline {section}{\numberline {4.2}Experiment set 1 results: Comparision of model performance}{26}{}%
\contentsline {subsection}{\numberline {4.2.1}Best predictive performance}{26}{}%
\contentsline {subsection}{\numberline {4.2.2}Performance of 'lightweight' models}{27}{}%
\contentsline {subsubsection}{Analyis of finetuning and inference time}{28}{}%
\contentsline {subsection}{\numberline {4.2.3}Deep-dive into the results}{29}{}%
\contentsline {section}{\numberline {4.3}Experiment set 2 results: Cross-domain results}{29}{}%
\contentsline {chapter}{\numberline {5}Conclusions}{30}{}%
\contentsline {chapter}{Appendices}{35}{}%
\contentsline {chapter}{\numberline {A}Other supporting analysis and graphs}{36}{}%
\contentsline {section}{\numberline {A.1}Breakdown of tweets in full dataset}{36}{}%
\contentsline {section}{\numberline {A.2}Sample data from dataset}{36}{}%
\contentsline {section}{\numberline {A.3}Token distribution after tokenization}{37}{}%
\contentsline {chapter}{\numberline {B}Other references}{38}{}%
\contentsline {section}{\numberline {B.1}Code Repository}{38}{}%
\contentsline {section}{\numberline {B.2}References for models used in experiment sets 1 and 2}{38}{}%
\contentsline {section}{\numberline {B.3}References for other models used}{38}{}%
\contentsline {section}{\numberline {B.4}Evaluation metrics references}{39}{}%
